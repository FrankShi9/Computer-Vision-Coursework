{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "SyFrOxe13ahD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rK-zVsXrkgl7"
      },
      "outputs": [],
      "source": [
        "class ConvLayer: # stride = 1\n",
        "  def __init__(self, kernel_cnt, kernel_size):\n",
        "    self.kernel_cnt = kernel_cnt\n",
        "    self.kernel_size = kernel_size\n",
        "    self.kernels = np.random.randn(kernel_cnt, kernel_size, kernel_size) / (kernel_size**2) # ref1a\n",
        "\n",
        "  def patch_gen(self, image):\n",
        "    h, w = image.shape\n",
        "    self.image = image\n",
        "    for h in range(h-self.kernel_size+1):\n",
        "      for w in range(w-self.kernel_size+1):\n",
        "        patch = image[h:h+self.kernel_size, w:w+self.kernel_size]\n",
        "        yield patch, h, w # gen\n",
        "\n",
        "  def forward(self, x):\n",
        "    h, w = x.shape\n",
        "    output = np.zeros((h-self.kernel_size+1, w-self.kernel_size+1, self.kernel_cnt))\n",
        "    for patch, h, w in self.patch_gen(x):\n",
        "      output[h,w] = np.sum(patch*self.kernels, axis=(1,2)) # ref1b\n",
        "    return output\n",
        "  \n",
        "  def backward(self, dE_dy, lr):\n",
        "    dE_dk = np.zeros(self.kernels.shape)\n",
        "    for patch, h, w in self.patch_gen(self.image):\n",
        "      for f in range(self.kernel_cnt):\n",
        "        dE_dk[f] += patch * dE_dy[h, w, f]\n",
        "    \n",
        "    self.kernels -= lr*dE_dk\n",
        "\n",
        "    return dE_dk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MaxPoolLayer:\n",
        "  def __init__(self, kernel_size):\n",
        "    self.kernel_size = kernel_size\n",
        "\n",
        "  def patch_gen(self, image):\n",
        "    out_h = image.shape[0] // self.kernel_size\n",
        "    out_w = image.shape[1] // self.kernel_size\n",
        "    self.image = image\n",
        "\n",
        "    for h in range(out_h):\n",
        "      for w in range(out_w):\n",
        "        patch = image[h*self.kernel_size:h*self.kernel_size+self.kernel_size, w*self.kernel_size:w*self.kernel_size+self.kernel_size]\n",
        "        yield patch, h, w\n",
        "\n",
        "  def forward(self, x):\n",
        "    h, w, kernel_cnt = x.shape\n",
        "    output = np.zeros((h//self.kernel_size, w//self.kernel_size, kernel_cnt))\n",
        "    for patch, h, w in self.patch_gen(x):\n",
        "      output[h,w] = np.amax(patch, axis=(0,1)) # ref2\n",
        "    return output\n",
        "  \n",
        "  def backward(self, dE_dy):\n",
        "    dE_dk = np.zeros(self.image.shape)\n",
        "    for patch, h, w in self.patch_gen(self.image):\n",
        "      h, w, kernel_cnt = patch.shape\n",
        "      max = np.amax(patch, axis=(0,1))\n",
        "\n",
        "      for ih in range(h):\n",
        "        for iw in range(w):\n",
        "          for ik in range(kernel_cnt):\n",
        "            if patch[ih,iw,ik] == max[ik]:\n",
        "              dE_dk[h*self.kernel_size+ih, w*self.kernel_size+iw, ik] = dE_dy[h, w, ik]\n",
        "\n",
        "    return dE_dk"
      ],
      "metadata": {
        "id": "dtqV4bKEhWaE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SoftmaxLayer:\n",
        "  def __init__(self, in_c, out_c):\n",
        "    self.weight = np.random.randn(in_c, out_c)/in_c\n",
        "    self.bias = np.zeros(out_c)\n",
        "\n",
        "  def forward(self, x):\n",
        "    self.ori_shape = x.shape\n",
        "    flat = x.flatten()\n",
        "    self.flat_in = flat\n",
        "    output_1 = np.dot(flat, self.weight) + self.bias\n",
        "    self.output = output_1\n",
        "    softmax_output = np.exp(output_1) / np.sum(np.exp(output_1), axis=0)\n",
        "    return softmax_output\n",
        "  \n",
        "  def backward(self, dE_dy, lr):\n",
        "    for i, grad in enumerate(dE_dy):\n",
        "      if grad == 0:\n",
        "        continue\n",
        "      transform = np.exp(self.output)\n",
        "      S = np.sum(transform)\n",
        "\n",
        "      dy_dz = -transform[i] * transform / (S**2)\n",
        "      dy_dz[i] = transform[i] * (S - transform[i]) / (S**2)\n",
        "\n",
        "      dz_dw = self.flat_in\n",
        "      dz_db = 1\n",
        "      dz_dx = self.weight\n",
        "\n",
        "      dE_dz = grad * dy_dz\n",
        "\n",
        "      dE_dw = dz_dw[np.newaxis].T @ dE_dz[np.newaxis]\n",
        "      dE_db = dE_dz * dz_db\n",
        "      dE_dX = dz_dx @ dE_dz\n",
        "\n",
        "      self.weight -= lr*dE_dw\n",
        "      self.bias -= lr*dE_db\n",
        " \n",
        "    return dE_dX.reshape(self.ori_shape)"
      ],
      "metadata": {
        "id": "ZO1GWOOCu7xf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(image, label, layers):\n",
        "  output = image/255\n",
        "  for layer in layers:\n",
        "    output = layer.forward(output)\n",
        "  \n",
        "  loss = -np.log(output[label])\n",
        "  acc = 1 if np.argmax(output) == label else 0\n",
        "  \n",
        "  return output, loss, acc"
      ],
      "metadata": {
        "id": "wCeBHKe4J2nK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backward(grad, layers, lr=5e-2):\n",
        "  grad = grad\n",
        "  for layer in layers[::-1]:\n",
        "    if type(layer) in [ConvLayer, SoftmaxLayer]:\n",
        "      grad = layer.backward(grad, lr)\n",
        "    elif type(layer) == MaxPoolLayer:\n",
        "      grad = layer.backward(grad)\n",
        "    \n",
        "    return grad"
      ],
      "metadata": {
        "id": "bnQpQoeuKWic"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(image, label, layers, lr=5e-2):\n",
        "  output, loss, acc = forward(image, label, layers)\n",
        "\n",
        "  grad = np.zeros(10)\n",
        "  grad[label] = -1/output[label]\n",
        "\n",
        "  grad_back = backward(grad, layers, lr)\n",
        "\n",
        "  return loss, acc"
      ],
      "metadata": {
        "id": "v21jiYF5JUvF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "X_train = X_train[:5000]\n",
        "y_train = y_train[:5000]\n",
        "\n",
        "# Define the network\n",
        "layers = [\n",
        "            ConvLayer(16,3), # layer with 8 3x3 filters, output (26,26,16)\n",
        "            MaxPoolLayer(2), # pooling layer 2x2, output (13,13,16)\n",
        "            SoftmaxLayer(13*13*16, 10) # softmax layer with 13*13*16 input and 10 output\n",
        "        ] \n",
        "\n",
        "for epoch in range(100):\n",
        "  print('Epoch {} ->'.format(epoch+1))\n",
        "  # Shuffle training data\n",
        "  permutation = np.random.permutation(len(X_train))\n",
        "  X_train = X_train[permutation]\n",
        "  y_train = y_train[permutation]\n",
        "  # Training the CNN\n",
        "  loss = 0\n",
        "  accuracy = 0\n",
        "  for i, (image, label) in enumerate(zip(X_train, y_train)):\n",
        "    if i % 1000 == 0:\n",
        "      print(\"Step {} average loss {}, accuracy {}%\".format(i+1, loss/1000, accuracy/10))\n",
        "      loss = 0\n",
        "      accuracy = 0\n",
        "    loss_1, accuracy_1 = train(image, label, layers)\n",
        "    loss += loss_1\n",
        "    accuracy += accuracy_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMfVzO8GzYXV",
        "outputId": "8e584a2f-fc5f-4b71-84f5-53371565a5ea"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 2.014081067518112, accuracy 30.7%\n",
            "Step 2001 average loss 1.782994766683324, accuracy 39.9%\n",
            "Step 3001 average loss 1.7267509236455436, accuracy 43.9%\n",
            "Step 4001 average loss 1.647880029700954, accuracy 46.0%\n",
            "Epoch 2 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.5748087444846675, accuracy 48.6%\n",
            "Step 2001 average loss 1.5793160853375938, accuracy 46.8%\n",
            "Step 3001 average loss 1.573720743040674, accuracy 47.3%\n",
            "Step 4001 average loss 1.53357469226331, accuracy 49.5%\n",
            "Epoch 3 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.5636079742992943, accuracy 49.0%\n",
            "Step 2001 average loss 1.4726490035267488, accuracy 51.7%\n",
            "Step 3001 average loss 1.5579761381663786, accuracy 48.5%\n",
            "Step 4001 average loss 1.4939525352036018, accuracy 48.9%\n",
            "Epoch 4 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.429630158699921, accuracy 52.4%\n",
            "Step 2001 average loss 1.5576642091869246, accuracy 49.4%\n",
            "Step 3001 average loss 1.4410397338397243, accuracy 51.6%\n",
            "Step 4001 average loss 1.4858547753143332, accuracy 50.5%\n",
            "Epoch 5 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.442235911521503, accuracy 50.6%\n",
            "Step 2001 average loss 1.510146991969009, accuracy 50.4%\n",
            "Step 3001 average loss 1.4773769299245127, accuracy 52.9%\n",
            "Step 4001 average loss 1.4909952905260753, accuracy 49.5%\n",
            "Epoch 6 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.3767018410178566, accuracy 56.2%\n",
            "Step 2001 average loss 1.4933669410968944, accuracy 51.0%\n",
            "Step 3001 average loss 1.447237784254744, accuracy 50.4%\n",
            "Step 4001 average loss 1.434217004896702, accuracy 53.1%\n",
            "Epoch 7 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.405792725748856, accuracy 52.0%\n",
            "Step 2001 average loss 1.442543395164925, accuracy 50.9%\n",
            "Step 3001 average loss 1.416187928516339, accuracy 53.5%\n",
            "Step 4001 average loss 1.4409876559973338, accuracy 52.6%\n",
            "Epoch 8 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.423144946542353, accuracy 54.8%\n",
            "Step 2001 average loss 1.4957521928190283, accuracy 50.2%\n",
            "Step 3001 average loss 1.3976194200254617, accuracy 54.5%\n",
            "Step 4001 average loss 1.387504928183423, accuracy 52.5%\n",
            "Epoch 9 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.4891504045053208, accuracy 50.9%\n",
            "Step 2001 average loss 1.3899481008693964, accuracy 54.7%\n",
            "Step 3001 average loss 1.4454963787919457, accuracy 51.0%\n",
            "Step 4001 average loss 1.3582070839963236, accuracy 54.9%\n",
            "Epoch 10 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.3621981288122307, accuracy 55.7%\n",
            "Step 2001 average loss 1.4329742589078758, accuracy 51.8%\n",
            "Step 3001 average loss 1.373612551995542, accuracy 56.1%\n",
            "Step 4001 average loss 1.426208123360235, accuracy 53.0%\n",
            "Epoch 11 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.4213593582251238, accuracy 51.6%\n",
            "Step 2001 average loss 1.372721518525988, accuracy 54.7%\n",
            "Step 3001 average loss 1.4124642386624697, accuracy 52.7%\n",
            "Step 4001 average loss 1.3772416177244369, accuracy 54.5%\n",
            "Epoch 12 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.3648441674116625, accuracy 53.7%\n",
            "Step 2001 average loss 1.3738479057352666, accuracy 54.0%\n",
            "Step 3001 average loss 1.3889674093512485, accuracy 55.3%\n",
            "Step 4001 average loss 1.4245937145730507, accuracy 53.4%\n",
            "Epoch 13 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.4068777708499343, accuracy 54.1%\n",
            "Step 2001 average loss 1.3223162038904244, accuracy 55.4%\n",
            "Step 3001 average loss 1.3502448702603234, accuracy 55.1%\n",
            "Step 4001 average loss 1.42291992309651, accuracy 52.0%\n",
            "Epoch 14 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.3292513994673092, accuracy 55.7%\n",
            "Step 2001 average loss 1.325361692367232, accuracy 55.6%\n",
            "Step 3001 average loss 1.3605791814300467, accuracy 54.6%\n",
            "Step 4001 average loss 1.4142784677993072, accuracy 54.6%\n",
            "Epoch 15 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2941695267083007, accuracy 58.5%\n",
            "Step 2001 average loss 1.332757642103694, accuracy 55.1%\n",
            "Step 3001 average loss 1.3783874896043105, accuracy 53.5%\n",
            "Step 4001 average loss 1.3824422806703678, accuracy 54.9%\n",
            "Epoch 16 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.3200686800415704, accuracy 54.8%\n",
            "Step 2001 average loss 1.3648330162468223, accuracy 54.1%\n",
            "Step 3001 average loss 1.42542344451297, accuracy 53.4%\n",
            "Step 4001 average loss 1.3357383575295696, accuracy 57.3%\n",
            "Epoch 17 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.349594203185766, accuracy 54.4%\n",
            "Step 2001 average loss 1.3656632401989708, accuracy 55.4%\n",
            "Step 3001 average loss 1.3289703027493838, accuracy 56.5%\n",
            "Step 4001 average loss 1.3513629834361134, accuracy 53.4%\n",
            "Epoch 18 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.341585071119028, accuracy 54.1%\n",
            "Step 2001 average loss 1.3146547385325145, accuracy 55.5%\n",
            "Step 3001 average loss 1.3432030456029505, accuracy 54.5%\n",
            "Step 4001 average loss 1.368620725709502, accuracy 54.4%\n",
            "Epoch 19 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.3016107001754, accuracy 55.6%\n",
            "Step 2001 average loss 1.3721419714303915, accuracy 55.0%\n",
            "Step 3001 average loss 1.333003642330129, accuracy 55.9%\n",
            "Step 4001 average loss 1.348738852726193, accuracy 53.5%\n",
            "Epoch 20 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.3378732864934824, accuracy 56.1%\n",
            "Step 2001 average loss 1.2692759342145512, accuracy 58.7%\n",
            "Step 3001 average loss 1.3395503920547487, accuracy 57.1%\n",
            "Step 4001 average loss 1.3729121633255175, accuracy 52.2%\n",
            "Epoch 21 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.3350175772687067, accuracy 54.7%\n",
            "Step 2001 average loss 1.3438813477019182, accuracy 55.7%\n",
            "Step 3001 average loss 1.3180904719589448, accuracy 54.8%\n",
            "Step 4001 average loss 1.3207844205115835, accuracy 57.1%\n",
            "Epoch 22 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.3652783523684404, accuracy 54.0%\n",
            "Step 2001 average loss 1.3240869691395367, accuracy 55.7%\n",
            "Step 3001 average loss 1.3102242257037675, accuracy 55.8%\n",
            "Step 4001 average loss 1.3715210755517173, accuracy 54.9%\n",
            "Epoch 23 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.337880119816914, accuracy 55.0%\n",
            "Step 2001 average loss 1.3458244689480334, accuracy 54.8%\n",
            "Step 3001 average loss 1.28574770152967, accuracy 55.8%\n",
            "Step 4001 average loss 1.3483970677580377, accuracy 54.9%\n",
            "Epoch 24 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.3305245594979513, accuracy 56.2%\n",
            "Step 2001 average loss 1.3024474274149405, accuracy 56.7%\n",
            "Step 3001 average loss 1.2821240776399447, accuracy 57.6%\n",
            "Step 4001 average loss 1.3468146511997476, accuracy 54.7%\n",
            "Epoch 25 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.3132223649217765, accuracy 55.5%\n",
            "Step 2001 average loss 1.3353576374815017, accuracy 53.9%\n",
            "Step 3001 average loss 1.326348586747476, accuracy 55.7%\n",
            "Step 4001 average loss 1.3359193178986108, accuracy 56.4%\n",
            "Epoch 26 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.257224974943074, accuracy 57.3%\n",
            "Step 2001 average loss 1.2730727576215985, accuracy 57.9%\n",
            "Step 3001 average loss 1.3119514462284392, accuracy 55.0%\n",
            "Step 4001 average loss 1.3541655709933937, accuracy 55.4%\n",
            "Epoch 27 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.315820713082311, accuracy 57.2%\n",
            "Step 2001 average loss 1.3344101680854157, accuracy 54.4%\n",
            "Step 3001 average loss 1.3314591623008352, accuracy 56.5%\n",
            "Step 4001 average loss 1.3271521548601855, accuracy 55.3%\n",
            "Epoch 28 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2601120551167777, accuracy 57.0%\n",
            "Step 2001 average loss 1.2751556890005036, accuracy 56.1%\n",
            "Step 3001 average loss 1.3154387132862544, accuracy 57.8%\n",
            "Step 4001 average loss 1.30352479740867, accuracy 54.2%\n",
            "Epoch 29 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2921235798955524, accuracy 55.4%\n",
            "Step 2001 average loss 1.3053076741790652, accuracy 55.1%\n",
            "Step 3001 average loss 1.3040036689476509, accuracy 56.7%\n",
            "Step 4001 average loss 1.3527609640421117, accuracy 54.6%\n",
            "Epoch 30 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.3379195617358879, accuracy 56.0%\n",
            "Step 2001 average loss 1.3011097406061243, accuracy 59.0%\n",
            "Step 3001 average loss 1.2948116393775109, accuracy 56.0%\n",
            "Step 4001 average loss 1.32468206307436, accuracy 53.6%\n",
            "Epoch 31 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.3057044786301577, accuracy 55.1%\n",
            "Step 2001 average loss 1.329489565506663, accuracy 55.7%\n",
            "Step 3001 average loss 1.2573369793548381, accuracy 58.5%\n",
            "Step 4001 average loss 1.321902201615037, accuracy 56.3%\n",
            "Epoch 32 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.3007540936346493, accuracy 56.2%\n",
            "Step 2001 average loss 1.3289867088238934, accuracy 55.5%\n",
            "Step 3001 average loss 1.308639573587428, accuracy 56.2%\n",
            "Step 4001 average loss 1.29457826855162, accuracy 56.0%\n",
            "Epoch 33 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2995941849402788, accuracy 54.8%\n",
            "Step 2001 average loss 1.2885055533279361, accuracy 56.7%\n",
            "Step 3001 average loss 1.2593426956150717, accuracy 58.1%\n",
            "Step 4001 average loss 1.3673103681594336, accuracy 53.7%\n",
            "Epoch 34 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.3000989614673373, accuracy 58.7%\n",
            "Step 2001 average loss 1.2436033492138234, accuracy 58.5%\n",
            "Step 3001 average loss 1.3229573177289387, accuracy 54.1%\n",
            "Step 4001 average loss 1.3389176120605035, accuracy 57.0%\n",
            "Epoch 35 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2324736689046678, accuracy 59.4%\n",
            "Step 2001 average loss 1.2938814727878343, accuracy 58.4%\n",
            "Step 3001 average loss 1.3044453215555456, accuracy 55.8%\n",
            "Step 4001 average loss 1.2824076227743746, accuracy 55.6%\n",
            "Epoch 36 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.3033004463546907, accuracy 56.9%\n",
            "Step 2001 average loss 1.2940771870627374, accuracy 58.2%\n",
            "Step 3001 average loss 1.2688115109098752, accuracy 56.8%\n",
            "Step 4001 average loss 1.2844044356020659, accuracy 56.4%\n",
            "Epoch 37 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2245852591896766, accuracy 57.8%\n",
            "Step 2001 average loss 1.2697139243478242, accuracy 57.4%\n",
            "Step 3001 average loss 1.3541295720409103, accuracy 54.2%\n",
            "Step 4001 average loss 1.277186722903592, accuracy 57.3%\n",
            "Epoch 38 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2871426321635133, accuracy 56.5%\n",
            "Step 2001 average loss 1.2720202364156905, accuracy 58.2%\n",
            "Step 3001 average loss 1.2891573957582176, accuracy 56.0%\n",
            "Step 4001 average loss 1.2858653252648202, accuracy 55.9%\n",
            "Epoch 39 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2775821114776007, accuracy 55.7%\n",
            "Step 2001 average loss 1.2691978710562337, accuracy 57.2%\n",
            "Step 3001 average loss 1.304729994193189, accuracy 55.6%\n",
            "Step 4001 average loss 1.2975014229483222, accuracy 54.8%\n",
            "Epoch 40 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2664357818727792, accuracy 55.9%\n",
            "Step 2001 average loss 1.2542002450652698, accuracy 58.2%\n",
            "Step 3001 average loss 1.318436377624557, accuracy 55.2%\n",
            "Step 4001 average loss 1.2394178740208008, accuracy 58.4%\n",
            "Epoch 41 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2765521639885609, accuracy 56.7%\n",
            "Step 2001 average loss 1.2625756483123598, accuracy 59.1%\n",
            "Step 3001 average loss 1.2838899830848214, accuracy 55.5%\n",
            "Step 4001 average loss 1.2864789392033822, accuracy 56.6%\n",
            "Epoch 42 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2815285728868373, accuracy 57.9%\n",
            "Step 2001 average loss 1.265910042479061, accuracy 58.3%\n",
            "Step 3001 average loss 1.2798645946460003, accuracy 56.1%\n",
            "Step 4001 average loss 1.2722512400414319, accuracy 56.0%\n",
            "Epoch 43 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2918229009752205, accuracy 56.5%\n",
            "Step 2001 average loss 1.2437152805541785, accuracy 57.9%\n",
            "Step 3001 average loss 1.2178289296934148, accuracy 59.2%\n",
            "Step 4001 average loss 1.28242934805501, accuracy 57.6%\n",
            "Epoch 44 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.294729708577187, accuracy 55.7%\n",
            "Step 2001 average loss 1.290410226737354, accuracy 55.5%\n",
            "Step 3001 average loss 1.2287481927936208, accuracy 59.4%\n",
            "Step 4001 average loss 1.2770907055855214, accuracy 56.1%\n",
            "Epoch 45 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2131298387233969, accuracy 59.4%\n",
            "Step 2001 average loss 1.2826403549437302, accuracy 56.2%\n",
            "Step 3001 average loss 1.2612699526967655, accuracy 58.0%\n",
            "Step 4001 average loss 1.280659131671147, accuracy 56.5%\n",
            "Epoch 46 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.3014592568904524, accuracy 56.4%\n",
            "Step 2001 average loss 1.2598794966541011, accuracy 55.3%\n",
            "Step 3001 average loss 1.2343538733460397, accuracy 58.0%\n",
            "Step 4001 average loss 1.2577660334056382, accuracy 58.6%\n",
            "Epoch 47 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2798109130289865, accuracy 56.5%\n",
            "Step 2001 average loss 1.237089120557764, accuracy 57.7%\n",
            "Step 3001 average loss 1.27375336487928, accuracy 55.7%\n",
            "Step 4001 average loss 1.2539576804717902, accuracy 57.7%\n",
            "Epoch 48 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2223595744279392, accuracy 58.9%\n",
            "Step 2001 average loss 1.2630327361341513, accuracy 57.2%\n",
            "Step 3001 average loss 1.2798913443264661, accuracy 55.5%\n",
            "Step 4001 average loss 1.2598062692704932, accuracy 57.5%\n",
            "Epoch 49 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.253023319465095, accuracy 56.3%\n",
            "Step 2001 average loss 1.2851961207928653, accuracy 56.0%\n",
            "Step 3001 average loss 1.2526595806500238, accuracy 59.2%\n",
            "Step 4001 average loss 1.2185321452119955, accuracy 60.1%\n",
            "Epoch 50 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.276205938297033, accuracy 56.0%\n",
            "Step 2001 average loss 1.2293215457348965, accuracy 59.6%\n",
            "Step 3001 average loss 1.2602266951434435, accuracy 56.7%\n",
            "Step 4001 average loss 1.2290984022019327, accuracy 60.9%\n",
            "Epoch 51 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2741314755464308, accuracy 57.1%\n",
            "Step 2001 average loss 1.2098437572029415, accuracy 58.7%\n",
            "Step 3001 average loss 1.248246343339997, accuracy 57.9%\n",
            "Step 4001 average loss 1.257069608252935, accuracy 58.3%\n",
            "Epoch 52 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2675938371288853, accuracy 56.0%\n",
            "Step 2001 average loss 1.1697510422616513, accuracy 59.2%\n",
            "Step 3001 average loss 1.24887633644215, accuracy 58.8%\n",
            "Step 4001 average loss 1.3011970796081924, accuracy 56.9%\n",
            "Epoch 53 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.3377420156389486, accuracy 55.9%\n",
            "Step 2001 average loss 1.276235150836079, accuracy 57.1%\n",
            "Step 3001 average loss 1.2335598448099063, accuracy 56.7%\n",
            "Step 4001 average loss 1.1891511075380325, accuracy 58.5%\n",
            "Epoch 54 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2122420603788253, accuracy 59.5%\n",
            "Step 2001 average loss 1.2320849259373492, accuracy 58.4%\n",
            "Step 3001 average loss 1.2650109379496166, accuracy 56.3%\n",
            "Step 4001 average loss 1.2279679548920293, accuracy 58.3%\n",
            "Epoch 55 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.203952682575992, accuracy 57.3%\n",
            "Step 2001 average loss 1.2407915279976307, accuracy 58.7%\n",
            "Step 3001 average loss 1.266126433304927, accuracy 58.2%\n",
            "Step 4001 average loss 1.2728942871682687, accuracy 57.9%\n",
            "Epoch 56 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2315509876446311, accuracy 58.3%\n",
            "Step 2001 average loss 1.2261882615237891, accuracy 57.4%\n",
            "Step 3001 average loss 1.2341437981756478, accuracy 59.3%\n",
            "Step 4001 average loss 1.299787496165349, accuracy 56.7%\n",
            "Epoch 57 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2893882363305469, accuracy 56.0%\n",
            "Step 2001 average loss 1.2612413334395216, accuracy 57.9%\n",
            "Step 3001 average loss 1.2352835461099205, accuracy 56.1%\n",
            "Step 4001 average loss 1.2001378218492211, accuracy 59.5%\n",
            "Epoch 58 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2454938983715111, accuracy 59.3%\n",
            "Step 2001 average loss 1.2042230783674917, accuracy 57.3%\n",
            "Step 3001 average loss 1.262669724744931, accuracy 55.3%\n",
            "Step 4001 average loss 1.2608542379952044, accuracy 56.7%\n",
            "Epoch 59 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2723355125826221, accuracy 56.8%\n",
            "Step 2001 average loss 1.2220224032766127, accuracy 57.1%\n",
            "Step 3001 average loss 1.3050089489660284, accuracy 56.0%\n",
            "Step 4001 average loss 1.213522783950052, accuracy 60.1%\n",
            "Epoch 60 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2114466761894331, accuracy 61.4%\n",
            "Step 2001 average loss 1.2830430830686217, accuracy 58.2%\n",
            "Step 3001 average loss 1.245729325376417, accuracy 56.1%\n",
            "Step 4001 average loss 1.2342516251238775, accuracy 58.0%\n",
            "Epoch 61 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.207921635138147, accuracy 59.2%\n",
            "Step 2001 average loss 1.2528173618224459, accuracy 56.7%\n",
            "Step 3001 average loss 1.2749757031621174, accuracy 56.9%\n",
            "Step 4001 average loss 1.2601356079253052, accuracy 55.9%\n",
            "Epoch 62 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2234019474206348, accuracy 57.8%\n",
            "Step 2001 average loss 1.272673730317807, accuracy 56.0%\n",
            "Step 3001 average loss 1.2528993015649825, accuracy 55.6%\n",
            "Step 4001 average loss 1.2725796292522367, accuracy 57.9%\n",
            "Epoch 63 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.240085695708951, accuracy 56.7%\n",
            "Step 2001 average loss 1.246229440870342, accuracy 59.0%\n",
            "Step 3001 average loss 1.2059869110985884, accuracy 59.7%\n",
            "Step 4001 average loss 1.2177275330518187, accuracy 59.2%\n",
            "Epoch 64 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.259163379901315, accuracy 56.9%\n",
            "Step 2001 average loss 1.2371666613825447, accuracy 59.1%\n",
            "Step 3001 average loss 1.2277012851620062, accuracy 59.1%\n",
            "Step 4001 average loss 1.2257835358354578, accuracy 58.7%\n",
            "Epoch 65 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.184016252813513, accuracy 58.6%\n",
            "Step 2001 average loss 1.2779559114613364, accuracy 56.2%\n",
            "Step 3001 average loss 1.257594906362856, accuracy 55.7%\n",
            "Step 4001 average loss 1.2244677190593765, accuracy 58.1%\n",
            "Epoch 66 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2338033586551311, accuracy 57.2%\n",
            "Step 2001 average loss 1.2979028154808516, accuracy 56.4%\n",
            "Step 3001 average loss 1.1725286045519567, accuracy 61.0%\n",
            "Step 4001 average loss 1.2066648068192085, accuracy 58.9%\n",
            "Epoch 67 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2231641168733645, accuracy 56.4%\n",
            "Step 2001 average loss 1.2371451514408347, accuracy 56.9%\n",
            "Step 3001 average loss 1.2706677565426479, accuracy 57.5%\n",
            "Step 4001 average loss 1.191292787823136, accuracy 59.7%\n",
            "Epoch 68 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2048571905572119, accuracy 57.5%\n",
            "Step 2001 average loss 1.2389432078298117, accuracy 58.8%\n",
            "Step 3001 average loss 1.252398946287537, accuracy 57.8%\n",
            "Step 4001 average loss 1.2450782998254468, accuracy 59.0%\n",
            "Epoch 69 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.171321338249595, accuracy 61.2%\n",
            "Step 2001 average loss 1.2809325461804135, accuracy 55.5%\n",
            "Step 3001 average loss 1.265586733699336, accuracy 55.8%\n",
            "Step 4001 average loss 1.2000084453510427, accuracy 58.7%\n",
            "Epoch 70 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2562014877682548, accuracy 57.4%\n",
            "Step 2001 average loss 1.2265574843130058, accuracy 58.2%\n",
            "Step 3001 average loss 1.229204944855811, accuracy 58.8%\n",
            "Step 4001 average loss 1.208721569411683, accuracy 58.7%\n",
            "Epoch 71 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.1887991286012574, accuracy 59.2%\n",
            "Step 2001 average loss 1.2163207460675218, accuracy 57.8%\n",
            "Step 3001 average loss 1.2704520433883488, accuracy 57.0%\n",
            "Step 4001 average loss 1.2301252454556049, accuracy 59.5%\n",
            "Epoch 72 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2097667633458307, accuracy 58.7%\n",
            "Step 2001 average loss 1.2307966891871067, accuracy 59.5%\n",
            "Step 3001 average loss 1.2150783457753596, accuracy 59.1%\n",
            "Step 4001 average loss 1.2548448577997837, accuracy 57.7%\n",
            "Epoch 73 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2173526640783636, accuracy 59.8%\n",
            "Step 2001 average loss 1.2426334836849355, accuracy 55.3%\n",
            "Step 3001 average loss 1.2618198853760036, accuracy 57.0%\n",
            "Step 4001 average loss 1.2025003890605792, accuracy 59.8%\n",
            "Epoch 74 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2484369703932068, accuracy 56.4%\n",
            "Step 2001 average loss 1.221472316444957, accuracy 58.9%\n",
            "Step 3001 average loss 1.2235621236289425, accuracy 59.0%\n",
            "Step 4001 average loss 1.2286443085368, accuracy 56.9%\n",
            "Epoch 75 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.1817418556486041, accuracy 60.9%\n",
            "Step 2001 average loss 1.220912905292706, accuracy 59.7%\n",
            "Step 3001 average loss 1.2922281712386579, accuracy 56.1%\n",
            "Step 4001 average loss 1.1869076088979025, accuracy 59.5%\n",
            "Epoch 76 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.174096792111528, accuracy 60.7%\n",
            "Step 2001 average loss 1.247206723652789, accuracy 58.3%\n",
            "Step 3001 average loss 1.2250726894105228, accuracy 59.9%\n",
            "Step 4001 average loss 1.2499480608783107, accuracy 55.4%\n",
            "Epoch 77 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.1871903299496742, accuracy 58.7%\n",
            "Step 2001 average loss 1.2503277434935718, accuracy 57.7%\n",
            "Step 3001 average loss 1.2422190623521423, accuracy 57.3%\n",
            "Step 4001 average loss 1.1761642810992303, accuracy 59.5%\n",
            "Epoch 78 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2019578466179126, accuracy 59.7%\n",
            "Step 2001 average loss 1.2411877602683279, accuracy 57.1%\n",
            "Step 3001 average loss 1.1987425533071403, accuracy 60.7%\n",
            "Step 4001 average loss 1.2262746738606305, accuracy 55.9%\n",
            "Epoch 79 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.1838120961777756, accuracy 60.6%\n",
            "Step 2001 average loss 1.2049484534320998, accuracy 59.3%\n",
            "Step 3001 average loss 1.2679059173700038, accuracy 55.6%\n",
            "Step 4001 average loss 1.1894317061137523, accuracy 58.6%\n",
            "Epoch 80 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.1900460388562892, accuracy 58.7%\n",
            "Step 2001 average loss 1.2415199212247374, accuracy 59.1%\n",
            "Step 3001 average loss 1.1717557124830476, accuracy 58.6%\n",
            "Step 4001 average loss 1.2485940254972046, accuracy 56.5%\n",
            "Epoch 81 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2415706004466636, accuracy 56.5%\n",
            "Step 2001 average loss 1.1951854366286034, accuracy 58.6%\n",
            "Step 3001 average loss 1.24448675162024, accuracy 56.8%\n",
            "Step 4001 average loss 1.2216114679163428, accuracy 59.4%\n",
            "Epoch 82 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.1703934899307913, accuracy 59.6%\n",
            "Step 2001 average loss 1.2584645310042064, accuracy 56.9%\n",
            "Step 3001 average loss 1.1922858665853653, accuracy 59.6%\n",
            "Step 4001 average loss 1.2764806625943674, accuracy 57.9%\n",
            "Epoch 83 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2614230062609855, accuracy 57.1%\n",
            "Step 2001 average loss 1.2329197482133532, accuracy 57.4%\n",
            "Step 3001 average loss 1.2152600416310064, accuracy 58.0%\n",
            "Step 4001 average loss 1.2341886413543623, accuracy 57.6%\n",
            "Epoch 84 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2122592930419114, accuracy 59.3%\n",
            "Step 2001 average loss 1.2363607841109439, accuracy 57.2%\n",
            "Step 3001 average loss 1.1733731731343267, accuracy 61.1%\n",
            "Step 4001 average loss 1.2348573211209366, accuracy 58.0%\n",
            "Epoch 85 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.158501190718645, accuracy 59.9%\n",
            "Step 2001 average loss 1.2784179028271005, accuracy 56.3%\n",
            "Step 3001 average loss 1.2237726670715925, accuracy 58.2%\n",
            "Step 4001 average loss 1.1950615322978966, accuracy 61.1%\n",
            "Epoch 86 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.241081738451693, accuracy 57.2%\n",
            "Step 2001 average loss 1.2182733908615477, accuracy 59.4%\n",
            "Step 3001 average loss 1.208573609772837, accuracy 57.5%\n",
            "Step 4001 average loss 1.1859694671125405, accuracy 59.5%\n",
            "Epoch 87 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2553284501002193, accuracy 57.0%\n",
            "Step 2001 average loss 1.2264791414436358, accuracy 58.9%\n",
            "Step 3001 average loss 1.1722946462518713, accuracy 59.1%\n",
            "Step 4001 average loss 1.1736669460573579, accuracy 59.8%\n",
            "Epoch 88 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.1832637966321435, accuracy 58.6%\n",
            "Step 2001 average loss 1.2175296961404019, accuracy 59.4%\n",
            "Step 3001 average loss 1.1614150672810912, accuracy 60.6%\n",
            "Step 4001 average loss 1.2189852581359546, accuracy 58.6%\n",
            "Epoch 89 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.1930156424540765, accuracy 59.1%\n",
            "Step 2001 average loss 1.1828183229657723, accuracy 59.6%\n",
            "Step 3001 average loss 1.216952707076253, accuracy 58.4%\n",
            "Step 4001 average loss 1.2554579579097656, accuracy 56.2%\n",
            "Epoch 90 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2024343640465884, accuracy 58.5%\n",
            "Step 2001 average loss 1.1600805051038472, accuracy 61.2%\n",
            "Step 3001 average loss 1.2573217343385579, accuracy 55.1%\n",
            "Step 4001 average loss 1.2227104291542068, accuracy 58.7%\n",
            "Epoch 91 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2472831027972284, accuracy 57.4%\n",
            "Step 2001 average loss 1.2043719841429166, accuracy 57.7%\n",
            "Step 3001 average loss 1.205729638700246, accuracy 59.2%\n",
            "Step 4001 average loss 1.2196546548946838, accuracy 57.9%\n",
            "Epoch 92 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2397325943866606, accuracy 57.3%\n",
            "Step 2001 average loss 1.1886370877039414, accuracy 59.2%\n",
            "Step 3001 average loss 1.2785288559447086, accuracy 55.5%\n",
            "Step 4001 average loss 1.1907027375972288, accuracy 58.0%\n",
            "Epoch 93 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2022913974084577, accuracy 58.0%\n",
            "Step 2001 average loss 1.2522744050470058, accuracy 57.0%\n",
            "Step 3001 average loss 1.1927412800162835, accuracy 58.5%\n",
            "Step 4001 average loss 1.224564449013094, accuracy 56.6%\n",
            "Epoch 94 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2012508854191375, accuracy 60.4%\n",
            "Step 2001 average loss 1.2128125045248757, accuracy 59.1%\n",
            "Step 3001 average loss 1.2357968299204887, accuracy 58.1%\n",
            "Step 4001 average loss 1.183924562589929, accuracy 59.9%\n",
            "Epoch 95 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.1806803534427472, accuracy 59.5%\n",
            "Step 2001 average loss 1.2288597605739675, accuracy 57.1%\n",
            "Step 3001 average loss 1.2209231857195955, accuracy 58.6%\n",
            "Step 4001 average loss 1.2509744104460034, accuracy 56.6%\n",
            "Epoch 96 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.1870049686098272, accuracy 60.0%\n",
            "Step 2001 average loss 1.1886478763465351, accuracy 59.2%\n",
            "Step 3001 average loss 1.2023137405300028, accuracy 58.7%\n",
            "Step 4001 average loss 1.2005688490933397, accuracy 57.9%\n",
            "Epoch 97 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2003593494123839, accuracy 60.0%\n",
            "Step 2001 average loss 1.2126852067048413, accuracy 56.8%\n",
            "Step 3001 average loss 1.2173873405987035, accuracy 58.8%\n",
            "Step 4001 average loss 1.2150236263561685, accuracy 58.2%\n",
            "Epoch 98 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2027974434200477, accuracy 59.1%\n",
            "Step 2001 average loss 1.1897299685090337, accuracy 59.5%\n",
            "Step 3001 average loss 1.238291403671084, accuracy 56.7%\n",
            "Step 4001 average loss 1.1956814071224755, accuracy 57.8%\n",
            "Epoch 99 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2278114262597495, accuracy 58.0%\n",
            "Step 2001 average loss 1.1856658970603577, accuracy 58.9%\n",
            "Step 3001 average loss 1.2327241465076435, accuracy 57.6%\n",
            "Step 4001 average loss 1.1804794531410094, accuracy 58.7%\n",
            "Epoch 100 ->\n",
            "Step 1 average loss 0.0, accuracy 0.0%\n",
            "Step 1001 average loss 1.2265066249920396, accuracy 58.7%\n",
            "Step 2001 average loss 1.1818014010479139, accuracy 58.3%\n",
            "Step 3001 average loss 1.2193999519846204, accuracy 56.9%\n",
            "Step 4001 average loss 1.1915419250517296, accuracy 60.2%\n"
          ]
        }
      ]
    }
  ]
}